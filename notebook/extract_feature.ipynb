{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to proceed with the following steps, we first need to place all the raw audio files in a specific folder, along with a `metadata.csv` file that contains the mapping between MSD `MSD_id` and LFM-1b `tracks_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mapping = pd.read_csv('mapping.csv')\n",
    "mapping_dict = dict(zip(mapping['MSD_id'], mapping['tracks_id:token']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MuQ Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, librosa\n",
    "from muq import MuQMuLan\n",
    "\n",
    "device = 'cuda'\n",
    "mulan = MuQMuLan.from_pretrained(\"OpenMuQ/MuQ-MuLan-large\", )\n",
    "mulan = mulan.to(device).eval()\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# Extract features and save as id:embedding in pkl format\n",
    "def traverse_and_extract_features(folder_path, output_path, mapping_dict):\n",
    "    features_dict = {}\n",
    "    names_ready = [os.path.splitext(file)[0] for file in os.listdir(output_path)]\n",
    "    \n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in tqdm(files):\n",
    "            if file.endswith('.mp3') or file.endswith('.wav'):\n",
    "                file_prefix = os.path.splitext(file)[0]\n",
    "                if file_prefix not in names_ready:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    wav, sr = librosa.load(file_path, sr=24000)\n",
    "                    wavs = torch.tensor(wav).unsqueeze(0).to(device)\n",
    "                    with torch.no_grad():\n",
    "                        audio_embeds = mulan(wavs=wavs)\n",
    "                    \n",
    "                    audio_embeds = audio_embeds.cpu().numpy()\n",
    "                    if file_prefix in mapping_dict:\n",
    "                        features_dict[mapping_dict[file_prefix]] = audio_embeds\n",
    "                    output_file = os.path.join(output_path, file_prefix + '.npy')\n",
    "                    np.save(output_file, audio_embeds)\n",
    "    \n",
    "    # Save features_dict to pkl\n",
    "    pkl_file_path = os.path.join(output_path, 'features.pkl')\n",
    "    with open(pkl_file_path, 'wb') as f:\n",
    "        pickle.dump(features_dict, f)\n",
    "\n",
    "folder_path = 'WAV_FILE_FOLDER_PATH'\n",
    "output_path = 'OUTPUT_PATH'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "traverse_and_extract_features(folder_path, output_path, mapping_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLAP Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msclap import CLAP\n",
    "\n",
    "# Load model (Choose between versions '2022' or '2023')\n",
    "# The model weight will be downloaded automatically if `model_fp` is not specified\n",
    "clap_model = CLAP(version = '2023', use_cuda=True)\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def traverse_and_extract_features(folder_path, output_path):\n",
    "\n",
    "    features_dict = {}\n",
    "    \n",
    "    names_ready = [ os.path.splitext(file)[0] for file in os.listdir(output_path)]\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in tqdm(files):\n",
    "            if file.endswith('.mp3'):\n",
    "                file_prefix = os.path.splitext(file)[0]\n",
    "                if file_prefix not in names_ready:\n",
    "\n",
    "                    file_paths = [os.path.join(root, file)]\n",
    "\n",
    "                    audio_embeds = clap_model.get_audio_embeddings(file_paths)\n",
    "\n",
    "                    audio_embeds = audio_embeds.cpu().numpy()\n",
    "                    if file_prefix in mapping_dict:\n",
    "                        features_dict[mapping_dict[file_prefix]] = audio_embeds\n",
    "                    output_file = os.path.join(output_path, file_prefix + '.npy')\n",
    "                    np.save(output_file, audio_embeds)\n",
    "    # Save features_dict to pkl\n",
    "    pkl_file_path = os.path.join(output_path, 'features.pkl')\n",
    "    with open(pkl_file_path, 'wb') as f:\n",
    "        pickle.dump(features_dict, f)\n",
    "\n",
    "folder_path = 'WAV_FILE_FOLDER_PATH' \n",
    "output_path = 'OUTPUT_PATH'  \n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "traverse_and_extract_features(folder_path, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zhouyz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
